{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to sears repository\n",
    "sys.path.append('sears') # noqa\n",
    "import paraphrase_scorer\n",
    "import onmt_model\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ID 0\n",
      "Loading model parameters.\n",
      "Loading model parameters.\n",
      "Loading model parameters.\n",
      "Loading model parameters.\n"
     ]
    }
   ],
   "source": [
    "ps = paraphrase_scorer.ParaphraseScorer(gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def load_polarity(path='/home/marcotcr/phd/datasets/sentiment-sentences/'):\n",
    "    data = []\n",
    "    labels = []\n",
    "    f_names = ['rt-polarity.neg', 'rt-polarity.pos']\n",
    "    for (l, f) in enumerate(f_names):\n",
    "        for line in open(os.path.join(path, f), 'rb'):\n",
    "            try:\n",
    "                line.decode('utf8')\n",
    "            except:\n",
    "                continue\n",
    "            data.append(line.decode('utf-8').strip().replace('. . .', '...'))\n",
    "            labels.append(l)\n",
    "    label_names = ['negative', 'positive']\n",
    "    return data, labels, label_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_polarity_imdb(path='/home/marcotcr/phd/datasets/sentiment-sentences-other/'):\n",
    "    data = []\n",
    "    labels = []\n",
    "    # f_names = ['amazon_cells_labelled.txt', 'imdb_labelled.txt', 'yelp_labelled.txt']\n",
    "    f_names = ['imdb_labelled.txt']\n",
    "    for (l, f) in enumerate(f_names):\n",
    "        for line in open(os.path.join(path, f), 'rb'):\n",
    "            try:\n",
    "                line.decode('utf8')\n",
    "            except:\n",
    "                continue\n",
    "            sentence, label = line.decode('utf-8').split('\\t')\n",
    "            label = int(label)\n",
    "            data.append(sentence.strip())\n",
    "            labels.append(label)\n",
    "    label_names = ['negative', 'positive']\n",
    "    return data, labels, label_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "import replace_rules\n",
    "tokenizer = replace_rules.Tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pickle.load(open('polarity.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_data['data']\n",
    "labels = all_data['labels']\n",
    "label_names = all_data['label_names']\n",
    "val = all_data['imdb']\n",
    "val_labels = all_data['imdb_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump({'data': data, 'labels': labels, 'label_names': label_names, 'imdb': val, 'imdb_labels': val_labels}, open('/tmp/polarity.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenizer.clean_for_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val, val_labels, _ = load_polarity_imdb()\n",
    "clean_val = tokenizer.clean_for_model(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train sequence length: 37\n",
      "Epoch 1/10\n",
      " - 3s - loss: 0.6873 - acc: 0.5634\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.6342 - acc: 0.7975\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.5142 - acc: 0.8750\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.3841 - acc: 0.9239\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.2802 - acc: 0.9594\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.2053 - acc: 0.9776\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.1520 - acc: 0.9868\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.1146 - acc: 0.9931\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.0880 - acc: 0.9949\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0687 - acc: 0.9965\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.FastTextClassifier()\n",
    "model.fit(data, labels, ngram_range=2, epochs=10, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(clean_val) == val_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_for_onmt = [' '.join([a.text for a in x]) for x in nlp.tokenizer.pipe(val)]\n",
    "val_for_onmt = [onmt_model.clean_text(x, only_upper=False) for x in val_for_onmt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = np.where(model.predict(clean_val) == val_labels)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_preds = np.array([val_labels[i] for i in right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_flips(instance, model, topk=10, threshold=-10, ):\n",
    "    orig_pred = model.predict([instance])[0]\n",
    "    instance_for_onmt = onmt_model.clean_text(' '.join([x.text for x in nlp.tokenizer(instance)]), only_upper=False)\n",
    "    paraphrases = ps.generate_paraphrases(instance_for_onmt, topk=topk, edit_distance_cutoff=4, threshold=threshold)\n",
    "    texts = tokenizer.clean_for_model(tokenizer.clean_for_humans([x[0] for x in paraphrases]))\n",
    "    preds = model.predict(texts)\n",
    "    fs = [(texts[i], paraphrases[i][1]) for i in np.where(preds != orig_pred)[0]]\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengliz/Repositories/sears/ENV/lib/python3.5/site-packages/torchtext/data/field.py:198: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n",
      "/home/zhengliz/Repositories/sears/ENV/lib/python3.5/site-packages/torchtext/data/field.py:197: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/home/zhengliz/Repositories/sears/ENV/lib/python3.5/site-packages/OpenNMT_py-0.1-py3.5.egg/onmt/Translator.py:113: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/zhengliz/Repositories/sears/ENV/lib/python3.5/site-packages/OpenNMT_py-0.1-py3.5.egg/onmt/Models.py:498: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/home/zhengliz/Repositories/sears/ENV/lib/python3.5/site-packages/OpenNMT_py-0.1-py3.5.egg/onmt/modules/GlobalAttention.py:143: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/zhengliz/Repositories/sears/ENV/lib/python3.5/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/home/zhengliz/Repositories/sears/ENV/lib/python3.5/site-packages/OpenNMT_py-0.1-py3.5.egg/onmt/Translator.py:63: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "sears/onmt_model.py:185: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  src_example = batch.dataset.examples[batch.indices[0].data[0]].src\n",
      "sears/onmt_model.py:191: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  m = int(maxIndex[0])\n",
      "sears/onmt_model.py:196: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  src_example = batch.dataset.examples[batch.indices[0].data[0]].src\n",
      "sears/onmt_model.py:202: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  m = int(maxIndex[0])\n",
      "sears/onmt_model.py:125: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  src_example = batch.dataset.examples[batch.indices[0].data[0]].src\n",
      "sears/onmt_model.py:137: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  def var(a): return Variable(a, volatile=True)\n",
      "sears/onmt_model.py:27: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  for e in decStates._all]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "orig_scores = {}\n",
    "flips = collections.defaultdict(lambda: [])\n",
    "for i, idx in enumerate(right):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    if val[idx] in flips:\n",
    "        continue\n",
    "    fs = find_flips(val[idx], model, topk=100, threshold=-10)\n",
    "    flips[val[idx]].extend([x[0] for x in fs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_val = [clean_val[i] for i in right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2 = replace_rules.TextToReplaceRules(nlp, right_val, [], min_freq=0.005, min_flip=0.00, ngram_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_rules = []\n",
    "rule_idx = {}\n",
    "rule_flips = {}\n",
    "for z, f in enumerate(flips):\n",
    "    rules = tr2.compute_rules(f, flips[f], use_pos=True, use_tags=True)\n",
    "    for rs in rules:\n",
    "        for r in rs:\n",
    "            if r.hash() not in rule_idx:\n",
    "                i = len(rule_idx)\n",
    "                rule_idx[r.hash()] = i\n",
    "                rule_flips[i] = []\n",
    "                frequent_rules.append(r)\n",
    "            i = rule_idx[r.hash()]\n",
    "            rule_flips[i].append(z)\n",
    "    if z % 500 == 0:\n",
    "        print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_right = tokenizer.tokenize(right_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frequent_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = time.time()\n",
    "rule_flips = {}\n",
    "rule_other_texts = {}\n",
    "rule_other_flips = {}\n",
    "rule_applies = {}\n",
    "for i, r in enumerate(frequent_rules):\n",
    "    idxs = list(tr2.get_rule_idxs(r))\n",
    "    to_apply = [token_right[x] for x in idxs]\n",
    "    applies, nt = r.apply_to_texts(to_apply, fix_apostrophe=False)\n",
    "    applies = [idxs[x] for x in applies]\n",
    "    old_texts = [right_val[i] for i in applies]\n",
    "    old_labels = right_preds[applies]\n",
    "    to_compute = [x for x in nt if x not in model_preds]\n",
    "    if to_compute:\n",
    "        preds = model.predict(to_compute)\n",
    "        for x, y in zip(to_compute, preds):\n",
    "            model_preds[x] = y\n",
    "    new_labels = np.array([model_preds[x] for x in nt])\n",
    "    where_flipped = np.where(new_labels != old_labels)[0]\n",
    "    flips = sorted([applies[x] for x in where_flipped])\n",
    "    rule_flips[i] = flips\n",
    "    rule_other_texts[i] = nt\n",
    "    rule_other_flips[i] = where_flipped\n",
    "    rule_applies[i] = applies\n",
    "    if i % 5000 == 0:\n",
    "        print(i)\n",
    "print(time.time() - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "really_frequent_rules = [i for i in range(len(rule_flips)) if len(rule_flips[i]) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_compute_score = collections.defaultdict(lambda: set())\n",
    "# for i in really_frequent_rules:\n",
    "#     orig_texts =  [right_val[z] for z in rule_applies[i]]\n",
    "#     new_texts = rule_other_texts[i]\n",
    "#     for o, n in zip(orig_texts, new_texts):\n",
    "#         to_compute_score[o].add(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -7.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_scores = {}\n",
    "for i, t in enumerate(right_val):\n",
    "    orig_scores[i] = ps.score_sentences(t, [t])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want rules s.t. the decile > -7.15. The current bottom 10% of a rule is always a lower bound on the decile, so if I see applies / 10 with score < -7.15 I can stop computing scores for that rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.last = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_scores = []\n",
    "rejected = set()\n",
    "for idx, i in enumerate(really_frequent_rules):\n",
    "    orig_texts =  [right_val[z] for z in rule_applies[i]]\n",
    "    orig_scor = [orig_scores[z] for z in rule_applies[i]]\n",
    "    scores = np.ones(len(orig_texts)) * -50\n",
    "#     if idx in rejected:\n",
    "#         rule_scores.append(scores)\n",
    "#         continue\n",
    "    decile = np.ceil(.1 * len(orig_texts))\n",
    "    new_texts = rule_other_texts[i]\n",
    "    bad_scores = 0\n",
    "    for j, (o, n, orig) in enumerate(zip(orig_texts, new_texts, orig_scor)):\n",
    "        if o not in ps_scores:\n",
    "            ps_scores[o] = {}\n",
    "        if n not in ps_scores[o]:\n",
    "            if n == '':\n",
    "                score = -40\n",
    "            else:\n",
    "                score = ps.score_sentences(o, [n])[0]\n",
    "            ps_scores[o][n] = min(0, score - orig)\n",
    "        scores[j] = ps_scores[o][n]\n",
    "        if ps_scores[o][n] < threshold:\n",
    "            bad_scores += 1\n",
    "        if bad_scores >= decile:\n",
    "            rejected.add(idx)\n",
    "            break\n",
    "    rule_scores.append(scores)\n",
    "            \n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump({'ps_scores': ps_scores, 'orig_scores': orig_scores}, open('/home/marcotcr/tmp/polarity_scoresz.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rule_scores) - len(rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_flip_scores = [rule_scores[i][rule_other_flips[really_frequent_rules[i]]] for i in range(len(rule_scores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_flips = [np.array(rule_applies[i])[rule_other_flips[i]] for i in really_frequent_rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_precsupports = [len(rule_applies[i]) for i in really_frequent_rules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule_picking import disqualify_rules\n",
    "threshold=-7.15\n",
    "# x = choose_rules_coverage(fake_scores, frequent_flips, frequent_supports,\n",
    "disqualified = disqualify_rules(rule_scores, frequent_flips,\n",
    "                          rule_precsupports, \n",
    "                      min_precision=0.0, min_flips=6, \n",
    "                         min_bad_score=threshold, max_bad_proportion=.10,\n",
    "                          max_bad_sum=999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(i, x.hash()) for (i, x) in enumerate(frequent_rules) if 'text_movie -> text_film' in x.hash()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rule_picking import choose_rules_coverage\n",
    "threshold=-7.15\n",
    "a = time.time()\n",
    "x = choose_rules_coverage(rule_flip_scores, frequent_flips, None,\n",
    "                          None, len(right_preds),\n",
    "                                frequent_scores_on_all=None, k=10, metric='max',\n",
    "                      min_precision=0.0, min_flips=0, exp=True,\n",
    "                         min_bad_score=threshold, max_bad_proportion=.1,\n",
    "                          max_bad_sum=999999,\n",
    "                         disqualified=disqualified,\n",
    "                         start_from=[])\n",
    "print(time.time() -a)\n",
    "support_denominator = float(len(right_preds))\n",
    "soup = lambda x: len(rule_applies[really_frequent_rules[x]]) / support_denominator \n",
    "prec = lambda x: frequent_flips[x].shape[0] / float(len(rule_scores[x]))\n",
    "fl = len(set([a for r in x for a in frequent_flips[r]]))\n",
    "print('Instances flipped: %d (%.2f)' % (fl, fl / float(len(right_preds))))\n",
    "print('\\n'.join(['%-5d %-5d %-5d %-35s f:%d avg_s:%.2f bad_s:%.2f bad_sum:%d Prec:%.2f Supp:%.2f' % (\n",
    "                i, x[i], really_frequent_rules[r],\n",
    "                frequent_rules[really_frequent_rules[r]].hash().replace('text_', '').replace('pos_', '').replace('tag_', ''),\n",
    "                frequent_flips[r].shape[0],\n",
    "                np.exp(rule_flip_scores[r]).mean(), (rule_scores[r] < threshold).mean(),\n",
    "                (rule_scores[r] < threshold).sum(), prec(r), soup(r)) for i, r in enumerate(x)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a couple of examples from the first rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in x:\n",
    "    rid = really_frequent_rules[r]\n",
    "    rule =  frequent_rules[rid]\n",
    "    print('Rule: %s' % rule.hash())\n",
    "    print()\n",
    "    for f in rule_flips[rid][:2]:\n",
    "        print('%s\\nP(positive):%.2f' % (right_val[f], model.predict_proba([right_val[f]])[0, 1]))\n",
    "        print()\n",
    "        new = rule.apply(token_right[f])[1]\n",
    "        print('%s\\nP(positive):%.2f' % (new, model.predict_proba([new])[0, 1]))\n",
    "        print()\n",
    "        print()\n",
    "    print('---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sears",
   "language": "python",
   "name": "sears"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
